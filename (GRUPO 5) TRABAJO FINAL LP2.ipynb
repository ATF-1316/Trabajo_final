{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando web scraping a la página UniProt\n",
    "\n",
    "## Presentado por:\n",
    "- Campuzano Galarza, Sofia Gabriela\n",
    "- Cordova Quispe, Brigitte Nayely\n",
    "- Tejada Flores, Antonella Franchesca\n",
    "\n",
    "## Objetivo\n",
    "Extraer información de la entrada (Entry), nombre de entrada (Entry name), proteína (Protein), gen (Gene), organismo (Organism), estado (Status) y GO-Proceso biológico (GO-Biological Process) de los más de seis mil genes abreviados (Gen Abrev) para posteriormente almacenarlos en un archivo excel.\n",
    "\n",
    "\n",
    "## ¿La página tiene un API?\n",
    "Tras una intensa busqueda, realizada por el grupo, pudimos validar que no existe API alguno para esta página. Por lo que, obtamos por inspeccionar de manera manual el html de la página y luego con ayuda del paquete BeautifulSoup pudimos extraer la data solicitada en el archivo Excel_UniProt_Vacio.xlsx.\n",
    "\n",
    "### Nota:\n",
    "- Se recomienda guardar el archivo ipynb y el excel vacío en la misma carpeta para que no haya problemas al ejecutar el código. \n",
    "\n",
    "- Este código esta trabajando con un archivo excel de nombre \"02 Ch Genes ordenados con vecinos_PROTOTIPO.xlsx\", ya que contiene una muestra de 16 genes. Si se desea correr todos los genes que existen en la página de **UniProt.org**, cambie el nombre del archivo excel por el de \"Excel_UniProt_Vacio.xlsx\". Debe realizar los cambios en la línea 5, 103 y 114.\n",
    "\n",
    "### Link de la página:\n",
    "https://www.uniprot.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ########################### PAQUETES A IMPORTAR ###########################\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "                ################## CÓDIGO INPLEMENTADO PARA EL WEB SCRAPING  ######################\n",
    "    \n",
    "archivo_vacio = pd.read_excel(\"02 Ch Genes ordenados con vecinos_PROTOTIPO.xlsx\",header=1) # Lee el archivo excel que se tiene guardada en la misma carpeta del script.\n",
    "genes=list(archivo_vacio[\"Gen Abrev\"]) # De la variable archivo_vacio que guarda la información del excel,\n",
    "# se extre la columna \"Gen Abrev\" para su posterior uso en la iteración a la hora de buscar gen por gen.\n",
    "\n",
    "\n",
    "n=3 # variable que itera y ubica la fila de genes en el archivo excel.\n",
    "for i in genes: # Por cada elemento en la lista de genes:\n",
    "    print(n-2,\":\",i)\n",
    "    url=f\"https://www.uniprot.org/uniprot/?query={i}+Capra+Hircus&sort=score\" # Guarda la url que va iterando cada fila de los elementos de la columna \"Gen Abrev\". \n",
    "    page_response=requests.get(url) # Hace una \"solicitud\" a la página del tipo \"obtener\" para extraer la información\n",
    "    # de la dirección de url.\n",
    "    page_content=BeautifulSoup(page_response.content,\"html.parser\") # Analiza la respuesta del \"page.response\" y lo guarda como\n",
    "    # un html para que pueda recorrer por el código fuente.\n",
    "    \n",
    "    \n",
    "    # Con el fin de entrar a la página de cada gen para extraer la información solicitado,\n",
    "    # Se realiza lo siguiente:\n",
    "\n",
    "    entry=page_content.find_all(\"td\",class_=\"entryID\") # Encuentra todos las etiquetas  \"td\" con las clase \"entryID\".\n",
    "    entry_i=[] # Lista vacía para almacenar la información que esta guardada en la variable entry.\n",
    "    for e in entry:  # Por cada elemento en entry:\n",
    "        entry_i.append(e.text) # Añade a la lista vacía solo el texto que encuente \"entry\".\n",
    "        \n",
    "        \n",
    "    # Utilizamos \"try\" porque a la hora de iterar buscando página por página y no encuentre nada de información en un gen,\n",
    "    # se pase a la búsqueda de otro gen. De esta manera evitamos errores en la extracción de información. \n",
    "        \n",
    "    try: # Intenta: \n",
    "        url=f\"https://www.uniprot.org/uniprot/{entry_i[0]}\" # Guarda la url de la página de cada gen, que se itera por el texto extraído de la primera fila de \"entry_i\"\n",
    "        page_response=requests.get(url) # Realiza la \"solicitud\" a la página del tipo \"obtener\" para extraer la información\n",
    "        # de la dirección url.\n",
    "        page_content=BeautifulSoup(page_response.content,\"html.parser\") # Analiza la respuesta del \"page.response\" y\n",
    "        # lo guarda como un html para que pueda recorrer por el código fuente.\n",
    "            \n",
    "            \n",
    "        ####  ENTRY  ####\n",
    "        entry_name=page_content.find_all(\"h2\",class_=\"page-title\") # Busca todas la etiquetas \"h2\" acompañada de la clase \"page-title\"\n",
    "        for j in entry_name: # Para cada elemento en entry_name:\n",
    "            entry1=j.text # extrae el texto que se encuentre en los elementos buscados de entry_name.\n",
    "        entry1=entry1.split() # Se utiliza la función split para separa los elementos de la lista.\n",
    "        Entry=entry1[2] # Como la lista se cuenta a partir del 0, se selecciona el elemento 2 de la lista entry1.  \n",
    "        \n",
    "        \n",
    "        #### ENTRY NAME ####\n",
    "        Entry_name=\"\".join(list(entry1[3])[1:len(list(entry1[3]))-1])\n",
    "        # De la lista entry1 selecciona el elemento 3, dicho elemento lo pasa a una lista, de dicha lista nueva \n",
    "        # selecciona a partir de la posición (1) toda la longitud hasta la ubicación (-1). De esta manera se evita las paréntesis.  \n",
    "        \n",
    "        \n",
    "        #### PROTEIN ####\n",
    "        proteina=page_content.find_all(\"h1\",property=\"name\") \n",
    "        for j in proteina:\n",
    "            Protein=j.text\n",
    "\n",
    "        #### GEN ####\n",
    "        gabrev=page_content.find_all(\"div\",class_='entry-overview-content',id=\"content-gene\")\n",
    "        for j in gabrev: \n",
    "            Gen_Abrev=j.text \n",
    "            \n",
    "       #### ORGANISMO ####\n",
    "        organism_gen=page_content.find_all(\"div\",class_='entry-overview-content',id=\"content-organism\")\n",
    "        for j in organism_gen:\n",
    "            ORGANISM_GEN=j.text\n",
    "        \n",
    "        #### STATUS ####\n",
    "        estado=page_content.find_all(\"a\",title=\"Unreviewed (TrEMBL)\", class_=\"icon-uniprot unreviewed-icon tooltipped\")\n",
    "        for j in estado:\n",
    "            ESTADO_PREVIO=j.text\n",
    "        ESTADO=str(ESTADO_PREVIO)\n",
    "\n",
    "    except:\n",
    "        Entry =\"\"\n",
    "        Entry_name =\"\"\n",
    "        Protein =\"\"\n",
    "        Gen_Abrev =\"\"\n",
    "        ORGANISM_GEN =\"\"\n",
    "        ESTADO =\"\"\n",
    "    \n",
    "    try:\n",
    "        url=f\"https://www.uniprot.org/uniprot/{entry_i[0]}\"\n",
    "        page=requests.get(url)\n",
    "        page_content=BeautifulSoup(page.content,\"html.parser\")\n",
    "        \n",
    "        #### GO BIOLOGICAL PROCESS ####  \n",
    "        go_secuencia = page_content.find(\"ul\", attrs= {\"class\":\"noNumbering biological_process\"})\n",
    "        for secuencia in go_secuencia:  \n",
    "            pro_biological_info = secuencia.find_all(\"a\", attrs={\"onclick\":\"window.ga('UniProt-Entry-View', 'click', 'Display-GO-Term');\"})\n",
    "            for j in range(len(pro_biological_info)):\n",
    "                GO_PROCESO.append(pro_biological_info[j].text)\n",
    "        GO_PROCESO=str(GO_PROCESO)\n",
    "        \n",
    "    except: \n",
    "        GO_PROCESO=\"\"\n",
    "        \n",
    "    excel=openpyxl.load_workbook(\"02 Ch Genes ordenados con vecinos_PROTOTIPO.xlsx\") \n",
    "    sheet=excel['Hoja1']\n",
    "    sheet.cell(row=n,column=2).value = Entry \n",
    "    sheet.cell(row=n,column=3).value = Entry_name \n",
    "    sheet.cell(row=n,column=4).value = Protein \n",
    "    sheet.cell(row=n,column=5).value = Gen_Abrev \n",
    "    sheet.cell(row=n,column=6).value = ORGANISM_GEN \n",
    "    sheet.cell(row=n,column=7).value = ESTADO \n",
    "    sheet.cell(row=n,column=8).value = GO_PROCESO \n",
    "    excel.save(\"02 Ch Genes ordenados con vecinos_PROTOTIPO.xlsx\") \n",
    "    n=n+1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
